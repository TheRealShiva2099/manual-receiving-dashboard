"""Local dashboard server for Manual Receiving ATC.

Design goals:
- localhost only (no network exposure)
- dead simple (YAGNI)
- serve an HTML file generated by the main app
- provide /api/events for future front-end improvements

Keep it small. Keep it readable. Zen puppy approved.
"""

from __future__ import annotations

import json
import os
import subprocess
import sys
import time
from pathlib import Path
from typing import Any

from flask import Flask, Response, jsonify, request, send_file


def _get_env_int(name: str, default: int) -> int:
    try:
        return int(os.environ.get(name, str(default)))
    except ValueError:
        return default


def _load_config(base_dir: Path) -> dict[str, Any]:
    cfg_path = base_dir / "atc_config.json"
    return json.loads(cfg_path.read_text(encoding="utf-8"))


def _bq_cmd(cfg: dict[str, Any]) -> list[str]:
    bq_path = str(cfg.get("bigquery", {}).get("bq_path", "bq")).strip() or "bq"
    job_project = cfg.get("bigquery", {}).get("job_project")
    billing_project = cfg.get("bigquery", {}).get("billing_project")
    project_id = job_project or billing_project

    base_args = [
        "query",
        "--quiet",
        "--use_legacy_sql=false",
        "--format=json",
    ]
    if project_id:
        base_args.append(f"--project_id={project_id}")

    return _resolve_bq_argv(bq_path) + base_args


def _resolve_bq_argv(bq_path: str) -> list[str]:
    """Return argv to invoke bq reliably.

    If bq_path is a Cloud SDK .cmd launcher, call the underlying
    `bin/bootstrapping/bq.py` directly.
    """

    p = Path(bq_path)
    if p.suffix.lower() in {".cmd", ".bat"}:
        cloudsdk_root = p.parent.parent
        bq_py = cloudsdk_root / "bin" / "bootstrapping" / "bq.py"
        bundled_python = cloudsdk_root / "platform" / "bundledpython" / "python.exe"
        python_exe = str(bundled_python) if bundled_python.exists() else sys.executable

        if not bq_py.exists():
            raise FileNotFoundError(f"Cloud SDK bq.py not found: {bq_py}")

        return [python_exe, str(bq_py)]

    return [bq_path]


def _run_bq_json(cfg: dict[str, Any], sql: str, timeout_s: int = 600) -> list[dict[str, Any]]:
    cmd = _bq_cmd(cfg)
    proc = subprocess.run(
        cmd,
        input=sql,
        capture_output=True,
        text=True,
        timeout=timeout_s,
        check=False,
        shell=False,
    )
    if proc.returncode != 0:
        details = (proc.stderr or proc.stdout or "").strip()
        raise RuntimeError(details or f"bq failed (exit={proc.returncode})")

    out = proc.stdout.strip()
    if not out:
        return []

    payload = json.loads(out)
    if not isinstance(payload, list):
        raise RuntimeError("Unexpected bq json output")
    return payload


def create_app(base_dir: Path) -> Flask:
    app = Flask(__name__)

    dashboard_path = base_dir / "atc_dashboard.html"
    template_path = base_dir / "dashboard_template.html"
    events_log_path = base_dir / "atc_events_log.json"
    status_path = base_dir / "atc_status.json"

    analytics_path = base_dir / "atc_analytics.html"
    analytics_template_path = base_dir / "analytics_template.html"
    viz_path = base_dir / "atc_viz.html"
    viz_template_path = base_dir / "viz_template.html"
    roster_path = base_dir / "atc_roster.html"
    roster_template_path = base_dir / "roster_template.html"
    roster_json_path = base_dir / "atc_roster.json"

    @app.get("/")
    def dashboard() -> Response:
        # Always serve something so the UI works even before the first BQ cycle finishes.
        if dashboard_path.exists():
            return send_file(dashboard_path)
        if template_path.exists():
            return send_file(template_path)
        return Response(
            "Dashboard template missing. Reinstall the ATC package.",
            status=500,
            mimetype="text/plain",
        )

    @app.get("/analytics")
    def analytics() -> Response:
        if analytics_path.exists():
            return send_file(analytics_path)
        if analytics_template_path.exists():
            return send_file(analytics_template_path)
        return Response(
            "Analytics template missing. Reinstall the ATC package.",
            status=500,
            mimetype="text/plain",
        )

    @app.get("/viz")
    def viz() -> Response:
        if viz_path.exists():
            return send_file(viz_path)
        if viz_template_path.exists():
            return send_file(viz_template_path)
        return Response(
            "Viz template missing. Reinstall the ATC package.",
            status=500,
            mimetype="text/plain",
        )

    @app.get("/roster")
    def roster() -> Response:
        if roster_path.exists():
            return send_file(roster_path)
        if roster_template_path.exists():
            return send_file(roster_template_path)
        return Response(
            "Roster template missing. Reinstall the ATC package.",
            status=500,
            mimetype="text/plain",
        )

    def _default_roster() -> dict[str, Any]:
        return {
            "version": 1,
            "updated_at": None,
            "roles": {
                "inbound": {"Shift A1": [], "Shift A2": [], "Shift B1": [], "Off Shift": []}
            },
        }

    @app.get("/api/roster")
    def api_roster_get() -> Response:
        if not roster_json_path.exists():
            roster_json_path.write_text(json.dumps(_default_roster(), indent=2), encoding="utf-8")

        try:
            payload = json.loads(roster_json_path.read_text(encoding="utf-8"))
        except json.JSONDecodeError:
            payload = _default_roster()

        if not isinstance(payload, dict):
            payload = _default_roster()

        return jsonify(payload)

    @app.post("/api/roster")
    def api_roster_post() -> Response:
        try:
            incoming = request.get_json(force=True)
        except Exception:
            return jsonify({"ok": False, "error": "Invalid JSON"}), 400

        if not isinstance(incoming, dict) or "roles" not in incoming:
            return jsonify({"ok": False, "error": "Invalid roster schema"}), 400

        roles = incoming.get("roles")
        if not isinstance(roles, dict):
            return jsonify({"ok": False, "error": "Invalid roles"}), 400

        def norm_list(x: Any) -> list[str]:
            if not isinstance(x, list):
                return []
            out: list[str] = []
            for v in x:
                s = str(v).strip().lower()
                if s and "@" in s:
                    out.append(s)
            return sorted(list(set(out)))

        # Normalize + enforce known shifts (inbound only)
        shifts = ["Shift A1", "Shift A2", "Shift B1", "Off Shift"]
        clean = _default_roster()
        src = roles.get("inbound", {}) if isinstance(roles.get("inbound"), dict) else {}
        for sh in shifts:
            clean["roles"]["inbound"][sh] = norm_list(src.get(sh, []))

        clean["updated_at"] = time.strftime("%Y-%m-%d %H:%M:%S")
        roster_json_path.write_text(json.dumps(clean, indent=2), encoding="utf-8")
        return jsonify({"ok": True, "roster": clean})

    @app.get("/api/events")
    def api_events() -> Response:
        if not events_log_path.exists():
            return jsonify({"events": []})

        try:
            payload: dict[str, Any] = json.loads(events_log_path.read_text(encoding="utf-8"))
        except json.JSONDecodeError:
            return jsonify({"events": []})

        # Always filter overflow/exempt locations at the API layer too.
        # This prevents old cached events from showing up after config changes.
        try:
            cfg = _load_config(base_dir)
            overflow = {str(x).strip().upper() for x in (cfg.get("monitoring", {}).get("overflow_locations", []) or [])}
        except Exception:
            overflow = set()

        events = payload.get("events", []) if isinstance(payload, dict) else []
        if overflow and isinstance(events, list):
            filtered = []
            for e in events:
                if not isinstance(e, dict):
                    continue
                loc = str(e.get("location_id", "")).strip()
                if loc and loc.strip().upper() in overflow:
                    continue
                filtered.append(e)
            payload["events"] = filtered

        return jsonify(payload)

    @app.get("/api/status")
    def api_status() -> Response:
        if not status_path.exists():
            return jsonify(
                {
                    "state": "starting",
                    "facility_id": None,
                    "tableau_url": "",
                    "last_query_start": None,
                    "last_query_end": None,
                    "last_error": None,
                }
            )
        try:
            payload: dict[str, Any] = json.loads(status_path.read_text(encoding="utf-8"))
        except json.JSONDecodeError:
            payload = {"state": "starting"}
        return jsonify(payload)

    def _cached_analytics_response(
        *,
        cache_path: Path,
        want_refresh: bool,
        min_refresh_seconds: int,
        build_rows: callable,
        now_epoch: int,
    ) -> Response:
        cached: dict[str, Any] | None = None
        if cache_path.exists():
            try:
                cached = json.loads(cache_path.read_text(encoding="utf-8"))
            except json.JSONDecodeError:
                cached = None

        last_refresh = int((cached or {}).get("refreshed_at_epoch", 0))
        can_refresh = (now_epoch - last_refresh) >= min_refresh_seconds

        if want_refresh and not can_refresh:
            wait_s = min_refresh_seconds - (now_epoch - last_refresh)
            return jsonify(
                {
                    "ok": True,
                    "cached": True,
                    "refreshed_at_epoch": last_refresh,
                    "min_refresh_seconds": min_refresh_seconds,
                    "message": f"Refresh throttled. Try again in ~{max(1, wait_s)}s.",
                    "rows": (cached or {}).get("rows", []),
                }
            )

        if want_refresh or cached is None:
            try:
                rows = build_rows()
                payload = {
                    "ok": True,
                    "cached": False,
                    "refreshed_at_epoch": now_epoch,
                    "rows": rows,
                }
                cache_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
                return jsonify(payload)
            except Exception as e:
                if cached is not None:
                    cached["ok"] = True
                    cached["cached"] = True
                    cached["message"] = f"Refresh failed; using cache: {e}"
                    return jsonify(cached)
                return jsonify({"ok": False, "error": str(e), "rows": []}), 500

        return jsonify(cached)

    @app.get("/api/top-items")
    def api_top_items() -> Response:
        cfg = _load_config(base_dir)
        top_cfg = cfg.get("analytics", {}).get("top_items", {})

        days = int(top_cfg.get("days", 30))
        limit = int(top_cfg.get("limit", 25))
        min_refresh_seconds = int(top_cfg.get("min_refresh_seconds", 300))
        cache_path = base_dir / str(top_cfg.get("cache_file", "top_items_cache.json"))

        want_refresh = request.args.get("refresh", "0") == "1"
        now_epoch = int(time.time())

        def build_rows() -> list[dict[str, Any]]:
            facility_id = str(cfg.get("monitoring", {}).get("facility_id", "US-07377"))

            sql = f"""
WITH
  r_latest AS (
    SELECT
      r.CONTAINER_ID,
      CAST(r.ITEM_NBR AS STRING) AS item_nbr,
      SAFE_DIVIDE(r.ITEM_QTY, NULLIF(r.VNPK_QTY, 0)) AS case_qty,
      r.ENTITY_OPERATION_TS
    FROM `wmt-edw-prod.US_SUPPLY_CHAIN_SCT_NONCAT_VM.RECEIVING_ITEM` r
    WHERE r.FACILITY = '{facility_id}'
      AND r.RCV_SET_ON_CONVEYOR_IND = TRUE
      AND r.CONTAINER_ID <> r.MESSAGE_ID
      AND r.ENTITY_OPERATION_TS >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
    QUALIFY ROW_NUMBER() OVER (
      PARTITION BY r.CONTAINER_ID, r.ITEM_NBR
      ORDER BY r.ENTITY_OPERATION_TS DESC
    ) = 1
  ),
  c_filtered AS (
    SELECT
      c.CONTAINER_ID,
      CAST(c.ITEM_NBR AS STRING) AS item_nbr,
      ANY_VALUE(CAST(c.ITEM_DESC AS STRING)) AS item_desc,
      ANY_VALUE(c.DELIVERY_NUMBER) AS DELIVERY_NUMBER
    FROM `wmt-edw-prod.US_SUPPLY_CHAIN_SCT_NONCAT_VM.CONTAINER_ITEM_OPERATIONS` c
    WHERE c.FACILITY = '{facility_id}'
      AND c.CONTAINER_CREATE_TS >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
      AND c.CONTAINER_ID IN (SELECT CONTAINER_ID FROM r_latest)
    GROUP BY c.CONTAINER_ID, c.ITEM_NBR
  ),
  vendor_map AS (
    SELECT
      d.DELIVERY_NUMBER,
      ANY_VALUE(o.VNDR_NAME) AS vendor_name
    FROM `wmt-edw-prod.US_SUPPLY_CHAIN_SCT_NONCAT_VM.DELIVERY_DOC` d
    LEFT JOIN `wmt-cp-prod.TRANS.ICC_ORD_SCH` o
      ON d.OMS_PO_NBR = CAST(o.OMS_PO_NBR AS STRING)
    WHERE d.DELIVERY_NUMBER IN (SELECT DELIVERY_NUMBER FROM c_filtered)
    GROUP BY d.DELIVERY_NUMBER
  )

SELECT
  COALESCE(v.vendor_name, '') AS vendor_name,
  r.item_nbr AS item_nbr,
  ANY_VALUE(c.item_desc) AS item_desc,
  SUM(r.case_qty) AS total_cases
FROM r_latest r
JOIN c_filtered c
  ON r.CONTAINER_ID = c.CONTAINER_ID
 AND r.item_nbr = c.item_nbr
LEFT JOIN vendor_map v
  ON c.DELIVERY_NUMBER = v.DELIVERY_NUMBER
GROUP BY vendor_name, item_nbr
ORDER BY total_cases DESC
LIMIT {limit}
""".strip()

            return _run_bq_json(cfg, sql, timeout_s=900)

        resp = _cached_analytics_response(
            cache_path=cache_path,
            want_refresh=want_refresh,
            min_refresh_seconds=min_refresh_seconds,
            build_rows=build_rows,
            now_epoch=now_epoch,
        )
        payload = resp.get_json() if hasattr(resp, "get_json") else None
        # enrich with metadata
        if isinstance(payload, dict):
            payload.setdefault("days", days)
            payload.setdefault("limit", limit)
            payload["days"] = days
            payload["limit"] = limit
            return jsonify(payload)
        return resp

    return app


def main() -> None:
    base_dir = Path(__file__).resolve().parent
    port = _get_env_int("ATC_PORT", 5000)
    host = os.environ.get("ATC_HOST", "127.0.0.1")

    app = create_app(base_dir)
    # No debug reloader: it spawns an extra process and breaks “silent” mode.
    app.run(host=host, port=port, debug=False, use_reloader=False)


if __name__ == "__main__":
    main()
